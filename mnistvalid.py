# -*- coding: utf-8 -*-
"""MnistValid.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1nS69Rzbbj_m-7F52P71TNg7BjxXX1CUA
"""

import torch
from torchvision import datasets, transforms
import torch.nn as nn
from torch.utils.data.sampler import SubsetRandomSampler

# prompt: create a vaildation set from this trainset

# define training and validation dataloaders
num_workers = 0
# percentage of training set to use as validation
valid_size = 0.2

# convert data to torch.FloatTensor
transform = transforms.ToTensor()

# choose the training and test datasets
train_data = datasets.MNIST(root='~/.pytorch/MNIST_data/', train=True,
                           download=True, transform=transform)
test_data = datasets.MNIST(root='~/.pytorch/MNIST_data/', train=False,
                          download=True, transform=transform)

# obtain training indices that will be used for validation
num_train = len(train_data)
indices = list(range(num_train))
import numpy as np
np.random.shuffle(indices)
split = int(np.floor(valid_size * num_train))
train_idx, valid_idx = indices[split:], indices[:split]

# define samplers for obtaining training and validation batches
train_sampler = SubsetRandomSampler(train_idx)
valid_sampler = SubsetRandomSampler(valid_idx)

# load training and validation data in batches
train_loader = torch.utils.data.DataLoader(train_data, batch_size=64,
                                           sampler=train_sampler, num_workers=num_workers)
valid_loader = torch.utils.data.DataLoader(train_data, batch_size=64,
                                           sampler=valid_sampler, num_workers=num_workers)

# load test data in batches
test_loader = torch.utils.data.DataLoader(test_data, batch_size=64,
                                          num_workers=num_workers)

class Mnist(nn.Module):
    def __init__(self):
        super().__init__()
        self.layer = nn.Sequential(nn.Flatten(), nn.Linear(28*28, 512),nn.ReLU(),nn.Dropout(0.2),nn.Linear(512,512),nn.ReLU(),nn.Dropout(0.2),nn.Linear(512,10))

    def forward(self, x):
        return self.layer(x)


device = "cuda"
model = Mnist()
loss_fn = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)
model = model.to(device)

epochs = 30
valid_min = np.inf

for e in range(epochs):
    train_loss = 0.0
    valid_loss = 0.0
    for images, label in train_loader:
        model.train()
        label = label.to(device)
        images = images.to(device)
        output = model(images)
        loss = loss_fn(output, label)
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
        train_loss += loss.item()
    for images, label in valid_loader:
        model.eval()
        images = images.to(device)
        label = label.to(device)
        output = model(images)
        loss = loss_fn(output, label)
        valid_loss += loss.item()
    print(f"Train_loss: {train_loss}, Valid_loss: {valid_loss}")
    if valid_loss<=valid_min:
        print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(
        valid_min,
        valid_loss))
        valid_min = valid_loss
        torch.save(model.state_dict(), 'model.pth')
    else:
      break

correct=0
total=0
with torch.no_grad():
    model.eval()
    for images, labels in test_loader:
        images = images.to(device)
        labels = labels.to(device)
        outputs = model(images)
        _, predicted = torch.max(outputs.data, 1)
        total += labels.size(0)
        correct += (predicted == labels).sum().item()
print(f"Accuracy: {100 * correct / total}")

